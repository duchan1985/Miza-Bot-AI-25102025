import os, time, logging, requests, feedparser, schedule, pytz, re
from datetime import datetime, timedelta
from dotenv import load_dotenv

# ======================
# CONFIG
# ======================
load_dotenv()
TELEGRAM_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
CHAT_IDS = [i.strip() for i in os.getenv("TELEGRAM_CHAT_IDS", "").split(",") if i.strip()]
VN_TZ = pytz.timezone("Asia/Ho_Chi_Minh")

DATA_DIR = "data"
SENT_FILE = os.path.join(DATA_DIR, "sent_links.txt")
LOG_FILE = "miza_news_final.log"
os.makedirs(DATA_DIR, exist_ok=True)
logging.basicConfig(filename=LOG_FILE, level=logging.INFO, format="%(asctime)s - %(message)s")

# ======================
# TELEGRAM
# ======================
def send_telegram(msg):
    """G·ª≠i tin nh·∫Øn Telegram"""
    url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
    for chat_id in CHAT_IDS:
        try:
            requests.post(url, json={"chat_id": chat_id, "text": msg, "parse_mode": "HTML"})
            logging.info(f"‚úÖ Sent to {chat_id}")
        except Exception as e:
            logging.error(f"‚ùå Telegram error: {e}")

# ======================
# STORAGE
# ======================
def load_sent():
    return set(open(SENT_FILE, encoding="utf-8").read().splitlines()) if os.path.exists(SENT_FILE) else set()

def save_sent(link):
    with open(SENT_FILE, "a", encoding="utf-8") as f:
        f.write(link + "\n")

# ======================
# FETCH GOOGLE NEWS & YOUTUBE RSS
# ======================
def fetch_feeds(days=7):
    """L·∫•y d·ªØ li·ªáu RSS t·ª´ Google News & YouTube"""
    now = datetime.now(VN_TZ)
    cutoff = now - timedelta(days=days)

    feeds = [
        "https://news.google.com/rss/search?q=Miza|MZG|Gi·∫•y+Miza|C√¥ng+ty+C·ªï+ph·∫ßn+Miza&hl=vi&gl=VN&ceid=VN:vi",
        "https://www.youtube.com/feeds/videos.xml?channel_id=UCd2aU53aTTxxLONczZc34BA"
    ]

    results = []
    for url in feeds:
        try:
            feed = feedparser.parse(url)
            for e in feed.entries:
                link = e.get("link", "")
                pub = e.get("published_parsed")
                if not pub:
                    continue
                pub_dt = datetime(*pub[:6], tzinfo=pytz.utc).astimezone(VN_TZ)
                if pub_dt < cutoff:
                    continue
                title = e.get("title", "Kh√¥ng c√≥ ti√™u ƒë·ªÅ")
                source = e.get("source", {}).get("title", "")
                results.append({
                    "title": title,
                    "link": link,
                    "date": pub_dt,
                    "source": source
                })
        except Exception as e:
            logging.error(f"RSS parse error for {url}: {e}")

    results.sort(key=lambda x: x["date"], reverse=True)
    return results

# ======================
# GI√Å C·ªî PHI·∫æU MZG üìà (C·∫¨P NH·∫¨T CHU·∫®N)
# ======================
def get_mzg_price():
    """
    L·∫•y gi√° MZG g·∫ßn nh·∫•t t·ª´ CafeF ho·∫∑c 24hMoney.
    N·∫øu l√† Th·ª© 7/CN -> t·ª± ƒë·ªông l·∫•y gi√° phi√™n Th·ª© 6 g·∫ßn nh·∫•t.
    """
    today = datetime.now(VN_TZ)
    weekday = today.weekday()
    if weekday >= 5:  # Th·ª© 7 ho·∫∑c CN
        target_day = today - timedelta(days=weekday - 4)
    else:
        target_day = today

    # ---- ∆ØU TI√äN CAFE.F ----
    try:
        url = "https://s.cafef.vn/upcom/MZG-cong-ty-co-phan-miza.chn"
        res = requests.get(url, timeout=10)
        res.encoding = "utf-8"

        # L·∫•y gi√° hi·ªán t·∫°i
        match_price = re.search(r'<div class="price-item[^>]*">([\d.,]+)</div>', res.text)
        # L·∫•y thay ƒë·ªïi %
        match_change = re.search(r'<div class="price-change[^>]*">([^<]+)</div>', res.text)
        # L·∫•y th·ªùi gian c·∫≠p nh·∫≠t (n·∫øu c√≥)
        match_time = re.search(r"C·∫≠p nh·∫≠t l√∫c\s*([\d: ]+\d{2}/\d{2})", res.text)

        if match_price:
            # x·ª≠ l√Ω gi√° -> 15.20 ho·∫∑c 15,200
            val = match_price.group(1).replace(",", "").replace(".", "")
            if len(val) > 3:
                price = float(val)
            else:
                price = float(match_price.group(1).replace(",", "."))
            change = match_change.group(1).strip() if match_change else "0%"
            updated_time = match_time.group(1) if match_time else target_day.strftime("%H:%M %d/%m")
            return price, change, updated_time

    except Exception as e:
        logging.error(f"CafeF fetch error: {e}")

    # ---- FALLBACK 24hMONEY ----
    try:
        url = "https://24hmoney.vn/ma-chung-khoan/MZG"
        res = requests.get(url, timeout=10)
        res.encoding = "utf-8"
        match = re.search(r'"currentPrice":\s*([\d.]+)', res.text)
        match_change = re.search(r'"changePercent":\s*"([^"]+)"', res.text)
        if match:
            price = float(match.group(1).replace(".", ""))
            change = match_change.group(1) if match_change else "N/A"
            updated_time = target_day.strftime("%H:%M %d/%m")
            return price, change, updated_time
    except Exception as e:
        logging.error(f"24hMoney fetch error: {e}")

    return None, None, None

# ======================
# SHORTEN URL
# ======================
def shorten_url(url):
    try:
        res = requests.get(f"https://is.gd/create.php?format=simple&url={url}", timeout=5)
        return res.text if res.status_code == 200 else url
    except:
        return url

# ======================
# FORMAT MESSAGE
# ======================
def format_message(news_list):
    lines = []
    for i, n in enumerate(news_list, 1):
        short = shorten_url(n["link"])
        src = f" - {n['source']}" if n["source"] else ""
        date_str = n["date"].strftime("%H:%M %d/%m/%Y")
        lines.append(f"{i}. <b>{n['title']}</b>{src}\nüóìÔ∏è {date_str}\nüîó {short}")
    return "\n\n".join(lines)

# ======================
# DAILY SUMMARY JOB (9h s√°ng)
# ======================
def job_daily_summary():
    news = fetch_feeds(days=7)
    price, change, updated_time = get_mzg_price()

    now = datetime.now(VN_TZ)
    header = f"üì¢ <b>T·ªïng h·ª£p tin Miza (7 ng√†y g·∫ßn nh·∫•t) - {now.strftime('%H:%M %d/%m')}</b>\n\n"
    if price:
        header += f"üìà Gi√° c·ªï phi·∫øu MZG: <b>{price:.2f} VNƒê</b> ({change})\nüïì C·∫≠p nh·∫≠t: {updated_time}\n\n"
    else:
        header += "‚ö†Ô∏è Kh√¥ng l·∫•y ƒë∆∞·ª£c gi√° MZG.\n\n"

    if not news:
        send_telegram(header + "‚ö†Ô∏è Kh√¥ng c√≥ tin m·ªõi v·ªÅ Miza.")
        return

    body = format_message(news[:15])
    send_telegram(header + body)
    logging.info("‚úÖ Sent daily summary.")

# ======================
# REAL-TIME MONITORING (5 ph√∫t)
# ======================
def job_realtime_check():
    sent = load_sent()
    new_items = []
    for item in fetch_feeds(days=2):
        if item["link"] not in sent:
            new_items.append(item)
            save_sent(item["link"])

    if new_items:
        now = datetime.now(VN_TZ)
        header = f"üÜï <b>Tin Miza m·ªõi (48h g·∫ßn nh·∫•t) - {now.strftime('%H:%M %d/%m')}</b>\n\n"
        body = format_message(new_items[:5])
        send_telegram(header + body)
        logging.info(f"üö® Sent {len(new_items)} new items.")
    else:
        print("‚è≥ Kh√¥ng c√≥ tin m·ªõi (check 5 ph√∫t).")

# ======================
# GI√Å C·ªî PHI·∫æU (9h, 12h, 15h)
# ======================
def job_stock_update():
    price, change, updated_time = get_mzg_price()
    now = datetime.now(VN_TZ)
    if price:
        msg = f"üìà Gi√° c·ªï phi·∫øu MZG: <b>{price:.2f} VNƒê</b> ({change})\nüïì C·∫≠p nh·∫≠t: {updated_time}"
    else:
        msg = f"üìâ Kh√¥ng l·∫•y ƒë∆∞·ª£c gi√° MZG l√∫c {now.strftime('%H:%M %d/%m')}"
    send_telegram(msg)
    logging.info("üìä Sent stock update.")

# ======================
# MAIN LOOP
# ======================
def main():
    logging.info("üöÄ Miza News Bot RSS started (FINAL).")
    send_telegram("üöÄ Miza News Bot RSS (FINAL) ‚Äì hi·ªÉn th·ªã ng√†y ƒëƒÉng th·∫≠t & gi√° MZG th·ª±c t·∫ø.")

    schedule.every().day.at("09:00").do(job_daily_summary)
    schedule.every().day.at("09:00").do(job_stock_update)
    schedule.every().day.at("12:00").do(job_stock_update)
    schedule.every().day.at("15:00").do(job_stock_update)
    schedule.every(5).minutes.do(job_realtime_check)

    job_realtime_check()
    job_stock_update()

    while True:
        schedule.run_pending()
        time.sleep(60)

if __name__ == "__main__":
    main()
