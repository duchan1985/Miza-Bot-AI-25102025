import os, time, logging, requests, feedparser, schedule, pytz, re
from datetime import datetime, timedelta
from dotenv import load_dotenv

# ======================
# CONFIG
# ======================
load_dotenv()
TELEGRAM_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
CHAT_IDS = [i.strip() for i in os.getenv("TELEGRAM_CHAT_IDS", "").split(",") if i.strip()]
VN_TZ = pytz.timezone("Asia/Ho_Chi_Minh")
RAPID_KEY = os.getenv("RAPID_API_KEY")

DATA_DIR = "data"
SENT_FILE = os.path.join(DATA_DIR, "sent_links.txt")
LOG_FILE = "miza_news_vn_v5.log"
os.makedirs(DATA_DIR, exist_ok=True)
logging.basicConfig(filename=LOG_FILE, level=logging.INFO, format="%(asctime)s - %(message)s")

# ======================
# TELEGRAM
# ======================
def send_telegram(msg):
    """G·ª≠i tin nh·∫Øn Telegram"""
    url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
    for chat_id in CHAT_IDS:
        try:
            requests.post(url, json={"chat_id": chat_id, "text": msg, "parse_mode": "HTML"})
            logging.info(f"‚úÖ Sent to {chat_id}")
        except Exception as e:
            logging.error(f"‚ùå Telegram error: {e}")

# ======================
# STORAGE
# ======================
def load_sent():
    """ƒê·ªçc danh s√°ch link ƒë√£ g·ª≠i"""
    return set(open(SENT_FILE, encoding="utf-8").read().splitlines()) if os.path.exists(SENT_FILE) else set()

def save_sent(link):
    """L∆∞u link ƒë√£ g·ª≠i"""
    with open(SENT_FILE, "a", encoding="utf-8") as f:
        f.write(link + "\n")

# ======================
# GOOGLE NEWS üáªüá≥
# ======================
def get_google_news(days=7):
    """L·∫•y tin Google News VN, ch·ªâ tin v·ªÅ Miza (MZG)"""
    feeds = [
        "https://news.google.com/rss/search?q=Miza|MZG|Gi·∫•y+Miza|C√¥ng+ty+C·ªï+ph·∫ßn+Miza|Nh√†+m√°y+Miza+Nghi+S∆°n&hl=vi&gl=VN&ceid=VN:vi"
    ]
    now = datetime.now(VN_TZ)
    cutoff = now - timedelta(days=days)
    results = []
    for url in feeds:
        feed = feedparser.parse(url)
        for e in feed.entries:
            link = e.get("link", "")
            pub = e.get("published_parsed") or e.get("updated_parsed")
            if not pub:
                continue
            pub_dt = datetime(*pub[:6], tzinfo=pytz.utc).astimezone(VN_TZ)
            if pub_dt.year != now.year or pub_dt < cutoff:
                continue
            title = e.get("title", "Kh√¥ng c√≥ ti√™u ƒë·ªÅ")
            if not any(k.lower() in title.lower() for k in ["miza", "mzg", "gi·∫•y", "nghi s∆°n"]):
                continue
            source = e.get("source", {}).get("title", "")
            results.append({"title": title, "link": link, "date": pub_dt, "source": source})
    results.sort(key=lambda x: x["date"], reverse=True)
    return results

# ======================
# YOUTUBE üáªüá≥
# ======================
def get_youtube_videos(query="MIZA CORP"):
    """L·∫•y video t·ª´ k√™nh MIZA ch√≠nh th·ª©c"""
    url = f"https://youtube138.p.rapidapi.com/search/?q={query}&hl=vi&gl=VN"
    headers = {"x-rapidapi-host": "youtube138.p.rapidapi.com", "x-rapidapi-key": RAPID_KEY}
    results = []
    try:
        res = requests.get(url, headers=headers, timeout=10)
        data = res.json()
        for item in data.get("contents", []):
            video = item.get("video")
            if not video:
                continue
            title = video.get("title", "")
            author = video.get("author", {}).get("title", "")
            if not any(k in (author + title).lower() for k in ["miza", "mzg"]):
                continue
            if any(x in title.lower() for x in ["myra", "remix", "show", "ca kh√∫c", "mv", "live", "tr·∫ßn", "music"]):
                continue
            vid = video.get("videoId")
            results.append({
                "title": title,
                "link": f"https://www.youtube.com/watch?v={vid}",
                "date": datetime.now(VN_TZ),
                "source": author or "YouTube"
            })
    except Exception as e:
        logging.error(f"YouTube API error: {e}")
    return results

# ======================
# GI√Å C·ªî PHI·∫æU MZG üìà
# ======================
def get_mzg_price():
    """L·∫•y gi√° c·ªï phi·∫øu MZG hi·ªán t·∫°i t·ª´ 24hmoney"""
    try:
        url = "https://24hmoney.vn/ma-chung-khoan/MZG"
        res = requests.get(url, timeout=10)
        res.encoding = "utf-8"
        match = re.search(r'(\d{1,3}(?:\.\d{3})*)(?:<\/div>\s*<div[^>]*>0\.00|\s*<\/span>)', res.text)
        if match:
            price = float(match.group(1).replace(".", ""))
            return price
    except Exception as e:
        logging.error(f"MZG price fetch error: {e}")
    return None

# ======================
# SHORTEN URL (is.gd)
# ======================
def shorten_url(url):
    """D√πng is.gd thay TinyURL (ƒë·∫£m b·∫£o m·ªü tr·ª±c ti·∫øp)"""
    try:
        r = requests.get(f"https://is.gd/create.php?format=simple&url={url}", timeout=5)
        return r.text if r.status_code == 200 else url
    except:
        return url

# ======================
# FORMAT
# ======================
def format_news(title, items):
    if not items:
        return ""
    lines = []
    for i, item in enumerate(items, 1):
        short = shorten_url(item["link"])
        src = f" - {item['source']}" if item.get("source") else ""
        date_str = item["date"].strftime("%d/%m/%Y %H:%M")
        lines.append(f"{i}. <b>{item['title']}</b>{src}\nüïì {date_str}\nüîó {short}")
    return f"<b>{title}</b>\n\n" + "\n\n".join(lines)

# ======================
# T·ªîNG H·ª¢P 9H S√ÅNG
# ======================
def job_daily_summary():
    now = datetime.now(VN_TZ)
    start_date = (now - timedelta(days=8)).strftime("%d/%m")
    end_date = (now - timedelta(days=1)).strftime("%d/%m/%Y")

    news = get_google_news(days=7)
    yt = get_youtube_videos("MIZA CORP")

    price = get_mzg_price()
    price_line = f"üìà Gi√° c·ªï phi·∫øu <b>MZG</b> hi·ªán t·∫°i: <b>{price:.2f} VND</b>\n\n" if price else "üìà Gi√° c·ªï phi·∫øu MZG: <i>ch∆∞a c·∫≠p nh·∫≠t</i>\n\n"

    header = f"üì¢ <b>T·ªïng h·ª£p tin Miza ({start_date} ‚Üí {end_date})</b>\n\n"
    body = format_news("üì∞ Tin t·ª©c b√°o ch√≠", news[:10]) + "\n\n" + format_news("üé• Video YouTube", yt[:5])
    send_telegram(price_line + header + body)
    logging.info("‚úÖ Sent daily summary.")

# ======================
# REALTIME 48H
# ======================
def job_realtime():
    sent = load_sent()
    new_items = []
    feeds = get_google_news(days=2) + get_youtube_videos("MIZA CORP")

    for item in feeds:
        if item["link"] not in sent:
            hours_diff = (datetime.now(VN_TZ) - item["date"]).total_seconds() / 3600
            if hours_diff <= 48:
                new_items.append(item)
                save_sent(item["link"])

    if new_items:
        now = datetime.now(VN_TZ)
        header = f"üÜï <b>Tin Miza m·ªõi (48h g·∫ßn nh·∫•t) - {now.strftime('%H:%M %d/%m')}</b>\n\n"
        body = format_news("B√†i m·ªõi ph√°t sinh", new_items[:10])
        send_telegram(header + body)
        logging.info(f"üö® Sent {len(new_items)} new items (48h).")
    else:
        print("‚è≥ Kh√¥ng c√≥ tin m·ªõi (check 20 ph√∫t).")

# ======================
# GI√Å C·ªî PHI·∫æU MZG (3 KHUNG GI·ªú)
# ======================
def job_stock_update():
    now = datetime.now(VN_TZ)
    price = get_mzg_price()
    if price:
        msg = f"üìà <b>Gi√° c·ªï phi·∫øu MZG</b> l√∫c {now.strftime('%H:%M %d/%m')} l√† <b>{price:.2f} VND</b>"
    else:
        msg = f"üìâ Kh√¥ng l·∫•y ƒë∆∞·ª£c gi√° MZG l√∫c {now.strftime('%H:%M %d/%m')}"
    send_telegram(msg)
    logging.info("üìä Sent stock update.")
    print(msg)

# ======================
# MAIN
# ======================
def main():
    logging.info("üöÄ Miza News Bot VN started (v5).")
    send_telegram("üöÄ Miza Bot VN kh·ªüi ƒë·ªông (v5) ‚Äì c√≥ th√™m l·ªãch c·∫≠p nh·∫≠t gi√° c·ªï phi·∫øu MZG 9h, 12h, 15h.")

    # G·ª≠i t·ªïng h·ª£p l√∫c 9h s√°ng
    schedule.every().day.at("09:00").do(job_daily_summary)

    # Tin m·ªõi 48h g·ª≠i m·ªói 20 ph√∫t
    schedule.every(20).minutes.do(job_realtime)

    # Gi√° c·ªï phi·∫øu MZG ‚Äì 3 l·∫ßn/ng√†y
    schedule.every().day.at("09:00").do(job_stock_update)
    schedule.every().day.at("12:00").do(job_stock_update)
    schedule.every().day.at("15:00").do(job_stock_update)

    # Ch·∫°y ngay l√∫c kh·ªüi ƒë·ªông
    job_realtime()
    job_stock_update()

    while True:
        schedule.run_pending()
        time.sleep(60)

if __name__ == "__main__":
    main()
